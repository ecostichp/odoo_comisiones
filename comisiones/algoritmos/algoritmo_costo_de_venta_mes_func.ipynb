{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import xmlrpc.client\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_params_func(test_db: bool = False) -> dict:\n",
    "\n",
    "    api_url = os.environ.get('ODOO_URL_API')\n",
    "    api_db = os.environ.get('ODOO_DB_API')\n",
    "    api_test_db = os.environ.get('ODOO_DB_PRUEBA_API')\n",
    "    api_username = os.environ.get('ODOO_USERNAME_API')\n",
    "    api_clave = os.environ.get('ODOO_CLAVE_API')\n",
    "\n",
    "\n",
    "    api_params = {}\n",
    "    if test_db:\n",
    "        api_params['api_db'] = api_test_db\n",
    "    else:\n",
    "        api_params['api_db'] = api_db\n",
    "\n",
    "\n",
    "    common = xmlrpc.client.ServerProxy(f'{api_url}/xmlrpc/2/common')\n",
    "    uid = common.authenticate(api_params['api_db'], api_username, api_clave, {})\n",
    "    models = xmlrpc.client.ServerProxy(f'{api_url}/xmlrpc/2/object')\n",
    "\n",
    "\n",
    "    api_params['api_clave'] = api_clave\n",
    "    api_params['api_uid'] = uid\n",
    "    api_params['api_models'] = models\n",
    "\n",
    "    return api_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_costo_ventas_func(mes: int, tolerance: list) -> list[str]:\n",
    "    \n",
    "    if type(mes) != int or mes < 1 or mes > 12:\n",
    "        raise Exception (f'El mes es incorrecto. El párametro \"mes\" debe ser un número entero entre 1 y 12. Escribiste: {mes}')\n",
    "    \n",
    "    if type(tolerance) != list or len(tolerance) != 2:\n",
    "        raise Exception (f'La tolerancia debe ser una lista de sólo dos elementos')\n",
    "\n",
    "    if type(tolerance[0]) != int or type(tolerance[1]) != int:\n",
    "        raise Exception (f'Los elementos de la lista de tolerancia deben ser sólo números tipo enteros')\n",
    "    \n",
    "    param_dia_hr_ini = pd.Timestamp(2024, mes, 1) + pd.Timedelta(hours=7)\n",
    "    param_dia_hr_fin = pd.Timestamp(2024, mes+1, 1) + pd.Timedelta(hours=7) - pd.Timedelta(seconds= 1)\n",
    "    \n",
    "    param_dia_hr_ini_tolerance = param_dia_hr_ini - pd.Timedelta(days = tolerance[0])\n",
    "    param_dia_hr_fin_tolerance = param_dia_hr_fin + pd.Timedelta(days = tolerance[1])\n",
    "    \n",
    "    search_costo_ventas = [\n",
    "        \"&\", \"&\",\n",
    "            (\"state\", \"in\", [\"purchase\", \"done\"]),\n",
    "            (\"date_approve\", \">=\", param_dia_hr_ini_tolerance.strftime('%Y-%m-%d %H:%M:%S')),\n",
    "            (\"date_approve\", \"<=\", param_dia_hr_fin_tolerance.strftime('%Y-%m-%d %H:%M:%S')),\n",
    "        ]\n",
    "\n",
    "    return search_costo_ventas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mes_to_string_func(mes: int) -> str:\n",
    "    \n",
    "    if type(mes) != int or mes < 1 or mes > 12:\n",
    "        raise Exception (f'El mes es incorrecto. El párametro \"mes\" debe ser un número entero entre 1 y 12. Escribiste: {mes}')\n",
    "    \n",
    "    match mes:\n",
    "        case 1:\n",
    "            mes_to_string = 'enero'\n",
    "        case 2:\n",
    "            mes_to_string = 'febrero'\n",
    "        case 3:\n",
    "            mes_to_string = 'marzo'\n",
    "        case 4:\n",
    "            mes_to_string = 'abril'\n",
    "        case 5:\n",
    "            mes_to_string = 'mayo'\n",
    "        case 6:\n",
    "            mes_to_string = 'junio'\n",
    "        case 7:\n",
    "            mes_to_string = 'julio'\n",
    "        case 8:\n",
    "            mes_to_string = 'agosto'\n",
    "        case 9:\n",
    "            mes_to_string = 'septiembre'\n",
    "        case 10:\n",
    "            mes_to_string = 'octubre'\n",
    "        case 11:\n",
    "            mes_to_string = 'noviembre'\n",
    "        case 12:\n",
    "            mes_to_string = 'diciembre'\n",
    "\n",
    "    return mes_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dfs_from_database(db_mode: str, mes_to_string:str) -> list[pd.DataFrame]:\n",
    "    \n",
    "    if db_mode.lower() == 'local':\n",
    "    \n",
    "        db_file_path_str = str(Path().cwd().parent.parent.joinpath(f'data/comisiones.db'))\n",
    "        engine = create_engine(f'sqlite:///{db_file_path_str}')\n",
    "\n",
    "        with engine.connect() as conn, conn.begin():\n",
    "            ventas = pd.read_sql_table(f'ventas_{mes_to_string}', conn, dtype_backend='numpy_nullable')\n",
    "            try:\n",
    "                ultimo_costo = pd.read_sql_table(f'ultimo_costo_{mes_to_string}', conn, dtype_backend='numpy_nullable')\n",
    "            except:\n",
    "                ultimo_costo = None\n",
    "\n",
    "        engine.dispose()\n",
    "    \n",
    "\n",
    "    elif db_mode.lower() != 'local':\n",
    "        raise Exception (f'Sólo existe la base de datos \"Local\"')\n",
    "\n",
    "\n",
    "    return ventas, ultimo_costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_df_from_excel(file_name:str, file_sheet:str, file_location:str) -> pd.DataFrame:\n",
    "\n",
    "    file_path_str = str(Path().cwd().parent.parent.joinpath(f'data/{file_location}/{file_name}'))\n",
    "    df = pd.read_excel(file_path_str, sheet_name=file_sheet, dtype_backend='numpy_nullable')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prov_locales_df_from_excel() -> list[pd.DataFrame]:\n",
    "    \n",
    "    file_name = 'proveedores_oficiales.xlsx'\n",
    "    file_sheet = 'Hoja1'\n",
    "    file_location = 'compras'\n",
    "\n",
    "    df = _get_df_from_excel(file_name, file_sheet, file_location)\n",
    "\n",
    "    prov_oficiales = df.loc[df['oficial'] == 1][['partner_id', 'partner_name']]\n",
    "    prov_locales = df.loc[df['oficial'] == 0][['partner_id', 'partner_name']]\n",
    "\n",
    "    return prov_oficiales, prov_locales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ultimo_costo_sae_df_from_excel() -> list[pd.DataFrame]:\n",
    "    \n",
    "    file_name = 'ultimo_costo_sae.xlsx'\n",
    "    file_sheet = 'Hoja1'\n",
    "    file_location = 'costo_ventas'\n",
    "\n",
    "    df = _get_df_from_excel(file_name, file_sheet, file_location)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calificados_fase_c_df_from_excel() -> list[pd.DataFrame]:\n",
    "\n",
    "    file_name = 'calificados_fase_c.xlsx'\n",
    "    file_sheet = 'Hoja1'\n",
    "    file_location = 'costo_ventas'\n",
    "\n",
    "    df = _get_df_from_excel(file_name, file_sheet, file_location)\n",
    "\n",
    "    # Check que verifica que todas las líneas de compra estén calificadas\n",
    "    if pd.NA in df['calificacion'].unique():\n",
    "        print('¡Cuidado!, tienes líneas de compras \"line_id\" sin calificar')\n",
    "        return None\n",
    "    \n",
    "    df['calificacion'] = df['calificacion'].str.upper()\n",
    "    calificados_fase_c_OK = df.loc[df['calificacion'] == 'OK'] # Líneas 'line_id' que tienen un match con 'fact_line_id'\n",
    "    calificados_fase_c_B = df.loc[df['calificacion'] == 'B'] # Líneas para regresar a la fase B y que el algoritmo las catalogue.\n",
    "    calificados_fase_c_C = df.loc[df['calificacion'] == 'C'] # Líneas para regresar a la fase C y que el humano las catalogue.\n",
    "    calificados_fase_c_D = df.loc[df['calificacion'] == 'D'] # Líneas para que el algoritmo fase D (final) las catalogue.\n",
    "    calificados_fase_c_E = df.loc[df['calificacion'] == 'E'] # Líneas para eliminar, la observación tiene el por qué.\n",
    "\n",
    "\n",
    "    return calificados_fase_c_OK, calificados_fase_c_B, calificados_fase_c_C, calificados_fase_c_D, calificados_fase_c_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_call_purchase_doc_func(api_params: dict, search_costo_ventas: list[str] ) -> list[int, dict]:\n",
    "    \n",
    "    api_db = api_params['api_db']\n",
    "    api_clave = api_params['api_clave']\n",
    "    uid = api_params['api_uid']\n",
    "    models = api_params['api_models']\n",
    "\n",
    "    purchase_doc_fields = [\n",
    "                    'name',\n",
    "                    'state',\n",
    "                    'partner_id',\n",
    "                    'partner_ref',\n",
    "                    'date_approve',\n",
    "                    'x_fecha_factura',\n",
    "                    'user_id',\n",
    "                    'create_uid'\n",
    "                    ]\n",
    "\n",
    "    purchase_doc_ids = models.execute_kw(api_db, uid, api_clave, 'purchase.order', 'search', [search_costo_ventas])\n",
    "    purchase_doc_json = models.execute_kw(api_db, uid, api_clave, 'purchase.order', 'read', [purchase_doc_ids], {'fields': purchase_doc_fields})\n",
    "    \n",
    "    return purchase_doc_ids, purchase_doc_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purchase_doc_func(purchase_doc_json: list[dict], prov_oficiales:pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    purchase_doc_data = []\n",
    "\n",
    "    for compra in purchase_doc_json:\n",
    "        new = {}\n",
    "        new['order_id'] = compra['id']\n",
    "        new['order_name'] = compra['name']\n",
    "        new['order_state'] = compra['state']\n",
    "        new['order_date'] = compra['date_approve'] if compra['date_approve'] else pd.NA\n",
    "        new['partner_id'] = compra['partner_id'][0]\n",
    "        new['partner_name'] = compra['partner_id'][1]\n",
    "        new['partner_fact_ref'] = compra['partner_ref']\n",
    "        new['partner_fact_date'] = compra['x_fecha_factura'] if compra['x_fecha_factura'] else pd.NA\n",
    "        new['capturista'] = compra['create_uid'][1] if compra['create_uid'] else pd.NA\n",
    "        new['vendedora'] = compra['user_id'][1] if compra['user_id'] else pd.NA\n",
    "\n",
    "        purchase_doc_data.append(new)\n",
    "\n",
    "    compras_doc = pd.DataFrame(purchase_doc_data)\n",
    "    compras_doc['order_date'] = pd.to_datetime(compras_doc['order_date'], format='%Y-%m-%d %H:%M:%S')\n",
    "    compras_doc['partner_fact_date'] = pd.to_datetime(compras_doc['partner_fact_date'], format='%Y-%m-%d')\n",
    "    compras_doc['oficial'] = compras_doc['partner_id'].isin(prov_oficiales['partner_id'])\n",
    "\n",
    "    return compras_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_call_purchase_line_func(api_params: dict, purchase_doc_ids: list[int]) -> list[dict]:\n",
    "    \n",
    "    api_db = api_params['api_db']\n",
    "    api_clave = api_params['api_clave']\n",
    "    uid = api_params['api_uid']\n",
    "    models = api_params['api_models']\n",
    "\n",
    "    purchase_line_fields = [\n",
    "                        'order_id',\n",
    "                        'date_approve',\n",
    "                        'partner_id',\n",
    "                        'product_id',\n",
    "                        'product_qty',\n",
    "                        'price_unit_discounted'\n",
    "                        ]\n",
    "\n",
    "    purchase_line_ids = models.execute_kw(api_db, uid, api_clave, 'purchase.order.line', 'search', [[(\"order_id.id\", \"in\", purchase_doc_ids)]])\n",
    "    purchase_line_json = models.execute_kw(api_db, uid, api_clave, 'purchase.order.line', 'read', [purchase_line_ids], {'fields': purchase_line_fields})\n",
    "    \n",
    "    return purchase_line_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purchase_line_func(purchase_line_json: list[dict]) -> pd.DataFrame:\n",
    "    \n",
    "    purchase_line_data = []\n",
    "\n",
    "    for line in purchase_line_json:\n",
    "        new = {}\n",
    "        new['line_id'] = line['id']\n",
    "        new['order_id'] = line['order_id'][0]\n",
    "        new['order_name'] = line['order_id'][1]\n",
    "        new['order_date'] = line['date_approve'] if line['date_approve'] else pd.NA\n",
    "        new['partner_id'] = line['partner_id'][0]\n",
    "        new['partner_name'] = line['partner_id'][1]\n",
    "        new['product_id_pp'] = line['product_id'][0]\n",
    "        new['product_name'] = line['product_id'][1]\n",
    "        new['product_qty'] = line['product_qty']\n",
    "        new['product_cost'] = line['price_unit_discounted']\n",
    "        \n",
    "        purchase_line_data.append(new)\n",
    "\n",
    "    compras_line = pd.DataFrame(purchase_line_data)\n",
    "    compras_line['order_date'] = pd.to_datetime(compras_line['order_date'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    return compras_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compras_func(compras_doc:pd.DataFrame, compras_line:pd.DataFrame, ultimo_costo:pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    compras_odoo = pd.merge(\n",
    "                    compras_line,\n",
    "                    compras_doc[['order_id', 'partner_fact_ref', 'partner_fact_date', 'capturista', 'vendedora']], \n",
    "                    how='left', \n",
    "                    on='order_id'\n",
    "                )\n",
    "\n",
    "    compras_odoo['order_date'] = compras_odoo['order_date'].dt.normalize()\n",
    "\n",
    "    cols_to_Int64 = ['line_id', 'order_id', 'partner_id', 'product_id_pp']\n",
    "    compras_odoo[cols_to_Int64] = compras_odoo[cols_to_Int64].astype('Int64')\n",
    "\n",
    "    compras_odoo['product_qty'] = compras_odoo['product_qty'].astype('Float64')\n",
    "    compras_odoo['vendedora'] = compras_odoo['vendedora'].convert_dtypes()\n",
    "\n",
    "    compras = pd.concat([compras_odoo, ultimo_costo])\n",
    "\n",
    "    return compras, compras_odoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mes = 2\n",
    "\n",
    "api_params = api_params_func()\n",
    "search_costo_ventas = search_costo_ventas_func(mes, tolerance=[0,0])\n",
    "mes_to_string = mes_to_string_func(mes)\n",
    "\n",
    "ventas, ultimo_costo = get_dfs_from_database('local', mes_to_string)\n",
    "\n",
    "prov_oficiales, prov_locales = prov_locales_df_from_excel()\n",
    "\n",
    "if not ultimo_costo:\n",
    "    ultimo_costo = ultimo_costo_sae_df_from_excel()\n",
    "calificados_fase_c_OK, calificados_fase_c_B, calificados_fase_c_C, calificados_fase_c_D, calificados_fase_c_E = calificados_fase_c_df_from_excel()\n",
    "\n",
    "purchase_doc_ids, purchase_doc_json = api_call_purchase_doc_func(api_params, search_costo_ventas)\n",
    "purchase_line_json = api_call_purchase_line_func(api_params, purchase_doc_ids)\n",
    "\n",
    "compras_doc = purchase_doc_func(purchase_doc_json, prov_oficiales)\n",
    "compras_line = purchase_line_func(purchase_line_json)\n",
    "compras, compras_odoo = compras_func(compras_doc, compras_line, ultimo_costo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Línea para comprobrar que el 100% de los proveedores de Odoo están calificados en la lista de proveedores oficiales\n",
    "\n",
    "check1 = (compras_doc[~compras_doc['partner_id'].isin(pd.concat([prov_locales, prov_oficiales])['partner_id'])]).drop_duplicates('partner_id')\n",
    "\n",
    "if not check1.empty:\n",
    "    print('Hay proveedores no calificados')\n",
    "    display(check1)\n",
    "\n",
    "else:\n",
    "    print('Todo correcto con check1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "check_costo_venta = (\n",
    "    pd.merge_asof(\n",
    "        left = ventas.sort_values('invoice_date'),\n",
    "        right = compras.sort_values('order_date'), \n",
    "        \n",
    "        left_by = 'product_id', \n",
    "        right_by = 'product_id_pp', \n",
    "        \n",
    "        left_on = 'invoice_date', \n",
    "        right_on = 'order_date', \n",
    "\n",
    "        direction = 'backward')\n",
    ")\n",
    "\n",
    "check2 = check_costo_venta[check_costo_venta['product_cost'].isna()][['product_id', 'product_name_x']]\n",
    "\n",
    "print(f'Hay {len(check2)} renglones sin costo de la venta.')\n",
    "\n",
    "if not check2.empty:\n",
    "    print('Los productos sin costo son los siguientes:')\n",
    "    display(check2.drop_duplicates('product_id'))\n",
    "\n",
    "else:\n",
    "    print('Todo correcto con check2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desarrollo del código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_capturistas = [\n",
    "       'Elsa Ivette Diaz Leyva',\n",
    "       'Alexa Yadira Mazariegos Zunun',\n",
    "       'Dulce Guadalupe Pedroza Valenzuela',\n",
    "       'Mariana Araceli Carvajal Flores',\n",
    "       'Rosario Martinez Zarate'\n",
    "]\n",
    "\n",
    "# Compras especiales que además no son de proveedores oficiales\n",
    "compras_especiales = compras_odoo.loc[\n",
    "            (~compras_odoo['vendedora'].isin(lista_capturistas))\n",
    "            & (~compras_odoo['partner_id'].isin(prov_oficiales['partner_id']))\n",
    "       ]\n",
    "\n",
    "# Resto de compras, es decir, compras de venta normal\n",
    "compras_no_especiales = compras_odoo.loc[\n",
    "              ~compras_odoo['line_id'].isin(compras_especiales['line_id'])\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_1_merge = (\n",
    "    pd.merge_asof(\n",
    "        left = compras_especiales.sort_values('order_date'), \n",
    "        right = ventas.sort_values('invoice_date'),\n",
    "        \n",
    "        left_by = ['product_id_pp', 'vendedora', 'product_qty'], \n",
    "        right_by = ['product_id', 'salesperson_name', 'quantity'], \n",
    "        \n",
    "        left_on = 'order_date', \n",
    "        right_on = 'invoice_date', \n",
    "\n",
    "        direction = 'nearest',\n",
    "        tolerance = pd.Timedelta(days=3))\n",
    ")\n",
    "\n",
    "ids_ventas_repetidas_por_corregir = match_1_merge.loc[\n",
    "                                                (~match_1_merge['fact_line_id'].isna()) \n",
    "                                                & (match_1_merge['fact_line_id'].duplicated())\n",
    "                                        ]['fact_line_id']\n",
    "\n",
    "ids_ventas_repetidas_por_corregir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_1ro_repetidos = pd.DataFrame([], columns=['line_id','fact_line_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repetidos_mini_df = match_1_merge.loc[match_1_merge['fact_line_id'].isin(ids_ventas_repetidas_por_corregir)].sort_values('line_id')\n",
    "repetidos_mini_df['diff'] = abs(repetidos_mini_df['invoice_date'] - repetidos_mini_df['order_date'])\n",
    "\n",
    "for id in ids_ventas_repetidas_por_corregir:\n",
    "        match_line_to_keep_wep = repetidos_mini_df.loc[repetidos_mini_df['fact_line_id'] == id].sort_values('diff').reset_index()[['line_id', 'fact_line_id']]\n",
    "        match_line_to_keep = match_line_to_keep_wep.loc[:0]\n",
    "\n",
    "        match_1ro_repetidos = pd.concat([match_1ro_repetidos, match_line_to_keep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_1ro_repetidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "añskldjfañlskjfñaskljfñaskdj fallar!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_1ro_repetidos = pd.DataFrame([], columns=['line_id','fact_line_id'])\n",
    "\n",
    "repetidos = True\n",
    "\n",
    "while repetidos:\n",
    "    \n",
    "    match_1_merge = (\n",
    "        pd.merge_asof(\n",
    "            left = compras_especiales.sort_values('order_date'), \n",
    "            right = ventas.sort_values('invoice_date'),\n",
    "            \n",
    "            left_by = ['product_id_pp', 'vendedora', 'product_qty'], \n",
    "            right_by = ['product_id', 'salesperson_name', 'quantity'], \n",
    "            \n",
    "            left_on = 'order_date', \n",
    "            right_on = 'invoice_date', \n",
    "\n",
    "            direction = 'nearest',\n",
    "            tolerance = pd.Timedelta(days=3))\n",
    "    )\n",
    "\n",
    "    ids_ventas_repetidas_por_corregir = match_1_merge.loc[\n",
    "                                                (~match_1_merge['fact_line_id'].isna()) \n",
    "                                                & (match_1_merge['fact_line_id'].duplicated())\n",
    "                                        ]['fact_line_id']\n",
    "    \n",
    "    if not ids_ventas_repetidas_por_corregir.empty:\n",
    "        repetidos_mini_df = match_1_merge.loc[match_1_merge['fact_line_id'].isin(ids_ventas_repetidas_por_corregir)].sort_values('line_id')\n",
    "        repetidos_mini_df['diff'] = abs(repetidos_mini_df['invoice_date'] - repetidos_mini_df['order_date'])\n",
    "\n",
    "        for id in ids_ventas_repetidas_por_corregir:\n",
    "            match_line_to_keep_wep = repetidos_mini_df.loc[repetidos_mini_df['fact_line_id'] == id].sort_values('diff').reset_index()[['line_id', 'fact_line_id']]\n",
    "            match_line_to_keep = match_line_to_keep_wep.loc[:0]\n",
    "\n",
    "            match_1ro_repetidos = pd.concat([match_1ro_repetidos, match_line_to_keep])\n",
    "\n",
    "        compras_especiales = compras_especiales[~compras_especiales['line_id'].isin(match_1ro_repetidos['line_id'])]\n",
    "        ventas = ventas[~ventas['fact_line_id'].isin(match_1ro_repetidos['fact_line_id'])]\n",
    "\n",
    "\n",
    "    if ids_ventas_repetidas_por_corregir.empty:        \n",
    "        print('Terminó el ciclo while')\n",
    "        repetidos = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match resultantes del 1er match.\n",
    "match_1 = match_1_merge.loc[~match_1_merge['fact_line_id'].isna(), ['line_id', 'fact_line_id']]\n",
    "\n",
    "# Después de correr el 1er match, las ventas restantes\n",
    "ventas_after_match_1 = ventas_after_repetidos.loc[\n",
    "                                ~ventas_after_repetidos['fact_line_id'].isin(match_1['fact_line_id'])\n",
    "                            ]\n",
    "\n",
    "# Después de correr el 1er match, las compras que tienen un product_id que sí existe en las ventas restantes.\n",
    "compras_especiales_after_match_1 = compras_especiales_after_repetidos.loc[\n",
    "                                            (~compras_especiales_after_repetidos['line_id'].isin(match_1['line_id']))\n",
    "                                            & (compras_especiales_after_repetidos['product_id_pp'].isin(ventas_after_match_1['product_id']))\n",
    "                                        ]\n",
    "\n",
    "# Después de correr el 1er match, resto de las compras especiales. Estan no tienen un product_id que existe en las ventas restantes y no se pueden merchar.\n",
    "compras_especiales_after_match_1_sin_linea_venta = compras_especiales_after_repetidos.loc[\n",
    "                                                            (~compras_especiales_after_repetidos['line_id'].isin(match_1['line_id']))\n",
    "                                                            & (~compras_especiales_after_repetidos['product_id_pp'].isin(ventas_after_match_1['product_id']))\n",
    "                                                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varias ventas para una sóla compra.\n",
    "match_2 = pd.DataFrame([], columns=['line_id','fact_line_id'])\n",
    "\n",
    "for i in range(len(compras_especiales_after_match_1)):\n",
    "    \n",
    "    linea_compra = compras_especiales_after_match_1.sort_values('order_date').iloc[i]\n",
    "\n",
    "    mini_df = ventas_after_match_1.loc[\n",
    "                (~ventas_after_match_1['fact_line_id'].isin(match_2['fact_line_id']))\n",
    "                & (ventas_after_match_1['salesperson_name'] == linea_compra['vendedora'])\n",
    "                & (ventas_after_match_1['product_id'] == linea_compra['product_id_pp'])\n",
    "            ]\n",
    "    \n",
    "    if not mini_df.empty:\n",
    "        df_copia = mini_df.copy()\n",
    "        df_copia['diff'] = abs(df_copia['invoice_date'] - linea_compra['order_date'])\n",
    "        df_sort = df_copia.sort_values('diff').reset_index()\n",
    "        df_sort['cumsum'] = df_sort['quantity'].cumsum()\n",
    "        index = df_sort[df_sort['cumsum'] == linea_compra['product_qty']].index[0] if not df_sort[df_sort['cumsum'] == linea_compra['product_qty']].index.empty else None\n",
    "        if index != None:\n",
    "            df_sort.loc[:index , 'line_id'] = linea_compra['line_id']\n",
    "            df_to_keep = df_sort.loc[~df_sort['line_id'].isna()]\n",
    "\n",
    "            if match_2.empty:\n",
    "                match_2 = df_to_keep[['line_id','fact_line_id']].copy()\n",
    "            else:\n",
    "                match_2 = pd.concat([\n",
    "                            match_2, \n",
    "                            df_to_keep[['line_id','fact_line_id']],\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Después de correr el 2do match, las ventas restantes\n",
    "ventas_after_match_2 = ventas_after_match_1.loc[\n",
    "                                ~ventas_after_match_1['fact_line_id'].isin(match_2['fact_line_id'])\n",
    "                            ]\n",
    "\n",
    "# Después de correr el 2do match, las compras que restan y que sí tendrán venta a la cual mercharse.\n",
    "compras_especiales_after_match_2 = compras_especiales_after_match_1.loc[\n",
    "                                            (~compras_especiales_after_match_1['line_id'].isin(match_2['line_id']))\n",
    "                                            & (compras_especiales_after_match_1['product_id_pp'].isin(ventas_after_match_2['product_id']))\n",
    "                                        ]\n",
    "\n",
    "# Después de correr el 2do match, resto de las compras especiales. Estan no tienen un product_id que existe en las ventas restantes y no se pueden merchar.\n",
    "compras_especiales_after_match_2_sin_linea_venta = compras_especiales_after_match_1.loc[\n",
    "                                                            (~compras_especiales_after_match_1['line_id'].isin(match_2['line_id']))\n",
    "                                                            & (~compras_especiales_after_match_1['product_id_pp'].isin(ventas_after_match_2['product_id']))\n",
    "                                                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varias compras para una sóla venta.\n",
    "match_3 = pd.DataFrame([], columns=['line_id','fact_line_id'])\n",
    "match_3_to_errase = pd.DataFrame([], columns=['line_id','fact_line_id'])\n",
    "\n",
    "ventas_inside_compras_especiales_after_match_2 = ventas_after_match_2[\n",
    "                                                    ventas_after_match_2['product_id'].isin(compras_especiales_after_match_2['product_id_pp'])\n",
    "                                                ]\n",
    "\n",
    "for i in range(len(ventas_inside_compras_especiales_after_match_2)):\n",
    "    \n",
    "    linea_venta = ventas_inside_compras_especiales_after_match_2.sort_values('invoice_date').iloc[i]\n",
    "\n",
    "    mini_df = compras_especiales_after_match_2.loc[\n",
    "                (~compras_especiales_after_match_2['line_id'].isin(match_3['line_id']))\n",
    "                & (compras_especiales_after_match_2['vendedora'] == linea_venta['salesperson_name'])\n",
    "                & (compras_especiales_after_match_2['product_id_pp'] == linea_venta['product_id'])\n",
    "            ]\n",
    "        \n",
    "\n",
    "    if not mini_df.empty:\n",
    "    \n",
    "        df_copia = mini_df.copy()\n",
    "        df_copia['diff'] = abs(df_copia['order_date'] - linea_venta['invoice_date'])\n",
    "        df_sort = df_copia.sort_values('diff').reset_index()\n",
    "        df_sort['cumsum'] = df_sort['product_qty'].cumsum()\n",
    "        index = df_sort[df_sort['cumsum'] == linea_venta['quantity']].index[0] if not df_sort[df_sort['cumsum'] == linea_venta['quantity']].index.empty else None\n",
    "        \n",
    "        if index != None:\n",
    "            df_sort.loc[:index , 'fact_line_id'] = linea_venta['fact_line_id']\n",
    "            \n",
    "            #Esta línea es para poder detectar la línea de compra con el costo mayor y dejarla para la línea de venta\n",
    "            df_to_keep = df_sort.loc[~df_sort['fact_line_id'].isna()].sort_values('product_cost', ascending=False)\n",
    "\n",
    "\n",
    "            if match_3.empty:\n",
    "                match_3 = df_to_keep.loc[:0, ['line_id', 'fact_line_id']].copy()\n",
    "                match_3_to_errase = df_to_keep[['line_id', 'fact_line_id']].copy()\n",
    "\n",
    "            else:\n",
    "                match_3 = pd.concat([\n",
    "                            match_3, \n",
    "                            df_to_keep.loc[:0, ['line_id', 'fact_line_id']],\n",
    "                        ])\n",
    "                match_3_to_errase = pd.concat([\n",
    "                            match_3_to_errase, \n",
    "                            df_to_keep[['line_id', 'fact_line_id']],\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Después de correr el 3er match, las ventas restantes\n",
    "ventas_after_match_3 = ventas_after_match_2.loc[\n",
    "                                ~ventas_after_match_2['fact_line_id'].isin(match_3_to_errase['fact_line_id'])\n",
    "                            ]\n",
    "\n",
    "# Después de correr el 3er match, las compras que restan y que sí tendrán venta a la cual mercharse.\n",
    "compras_especiales_after_match_3 = compras_especiales_after_match_2.loc[\n",
    "                                            (~compras_especiales_after_match_2['line_id'].isin(match_3_to_errase['line_id']))\n",
    "                                            & (compras_especiales_after_match_2['product_id_pp'].isin(ventas_after_match_3['product_id']))\n",
    "                                        ]\n",
    "\n",
    "# Después de correr el 3er match, resto de las compras especiales. Estan no tienen un product_id que existe en las ventas restantes y no se pueden merchar.\n",
    "compras_especiales_after_match_3_sin_linea_venta = compras_especiales_after_match_2.loc[\n",
    "                                                            (~compras_especiales_after_match_2['line_id'].isin(match_3_to_errase['line_id']))\n",
    "                                                            & (~compras_especiales_after_match_2['product_id_pp'].isin(ventas_after_match_3['product_id']))\n",
    "                                                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_4_merge = (\n",
    "    pd.merge_asof(\n",
    "        left = ventas_after_match_3.sort_values('invoice_date'), \n",
    "        right = compras_especiales_after_match_3.sort_values('order_date'),\n",
    "        \n",
    "        left_by = ['product_id'], \n",
    "        right_by = ['product_id_pp'], \n",
    "        \n",
    "        left_on = 'invoice_date', \n",
    "        right_on = 'order_date', \n",
    "\n",
    "        direction = 'nearest',\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match resultantes del 4to match.\n",
    "match_4 = match_4_merge.loc[~match_4_merge['line_id'].isna(), ['line_id', 'fact_line_id']]\n",
    "\n",
    "# Después de correr el 1er match, las ventas restantes\n",
    "ventas_after_match_4 = ventas_after_match_3.loc[\n",
    "                                ~ventas_after_match_3['fact_line_id'].isin(match_4['fact_line_id'])\n",
    "                            ]\n",
    "\n",
    "# Después de correr el 4to match, las compras que tienen un product_id que sí existe en las ventas restantes.\n",
    "compras_especiales_after_match_4 = compras_especiales_after_match_3.loc[\n",
    "                                            (~compras_especiales_after_match_3['line_id'].isin(match_1['line_id']))\n",
    "                                            & (compras_especiales_after_match_3['product_id_pp'].isin(ventas_after_match_4['product_id']))\n",
    "                                        ]\n",
    "\n",
    "# Después de correr el 4to match, resto de las compras especiales. Estan no tienen un product_id que existe en las ventas restantes y no se pueden merchar.\n",
    "compras_especiales_after_match_4_sin_linea_venta = compras_especiales_after_match_3.loc[\n",
    "                                                            (~compras_especiales_after_match_3['line_id'].isin(match_1['line_id']))\n",
    "                                                            & (~compras_especiales_after_match_3['product_id_pp'].isin(ventas_after_match_4['product_id']))\n",
    "                                                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check donde se verifíca que ya no hay más compras especiales por merchar, es decir, ya no se ocupa un match_5.\n",
    "check3 = compras_especiales_after_match_4.empty\n",
    "\n",
    "if check3:\n",
    "    print('Check 3: ¡Se acabaron las compras especiales!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_compras_especiales = pd.concat([match_1, match_2, match_3, match_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check donde todas las líneas compras especiales están unidas a líneas de ventas\n",
    "all_line_ids_proceced = (\n",
    "        pd.concat(\n",
    "            [\n",
    "                repetidos_match_1ro['line_id'],\n",
    "                match_1['line_id'],\n",
    "                compras_especiales_after_match_1_sin_linea_venta['line_id'],\n",
    "                match_2['line_id'],\n",
    "                compras_especiales_after_match_2_sin_linea_venta['line_id'],\n",
    "                match_3_to_errase['line_id'],\n",
    "                compras_especiales_after_match_3_sin_linea_venta['line_id'],\n",
    "                match_4['line_id'],\n",
    "                compras_especiales_after_match_4_sin_linea_venta['line_id'],\n",
    "            ]\n",
    "        )\n",
    "        .drop_duplicates()\n",
    "        .sort_values()\n",
    "        .astype('Int64')\n",
    "        .reset_index()\n",
    "        ['line_id']\n",
    "    )\n",
    "\n",
    "all_line_ids_to_proces = (\n",
    "        compras_especiales['line_id']\n",
    "        .sort_values()\n",
    "        .reset_index()\n",
    "        ['line_id']\n",
    "    )\n",
    "\n",
    "check4 = all_line_ids_proceced.equals(all_line_ids_to_proces)\n",
    "\n",
    "if check4:\n",
    "    print('Check 4: Todas las líneas de compra especiales fueron procesadas. Puedes continuar con las compras no especiales.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_comisiones-Odoo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
